{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12323346,"sourceType":"datasetVersion","datasetId":7767864}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd \ndf = pd.read_csv(\"/kaggle/input/qadataset/100_Unique_QA_Dataset.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T19:52:11.596412Z","iopub.execute_input":"2025-06-29T19:52:11.596694Z","iopub.status.idle":"2025-06-29T19:52:14.260284Z","shell.execute_reply.started":"2025-06-29T19:52:11.596672Z","shell.execute_reply":"2025-06-29T19:52:14.258977Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T19:52:16.237799Z","iopub.execute_input":"2025-06-29T19:52:16.238157Z","iopub.status.idle":"2025-06-29T19:52:16.268883Z","shell.execute_reply.started":"2025-06-29T19:52:16.238131Z","shell.execute_reply":"2025-06-29T19:52:16.267999Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                          question      answer\n0                   What is the capital of France?       Paris\n1                  What is the capital of Germany?      Berlin\n2               Who wrote 'To Kill a Mockingbird'?  Harper-Lee\n3  What is the largest planet in our solar system?     Jupiter\n4   What is the boiling point of water in Celsius?         100","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What is the capital of France?</td>\n      <td>Paris</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>What is the capital of Germany?</td>\n      <td>Berlin</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Who wrote 'To Kill a Mockingbird'?</td>\n      <td>Harper-Lee</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What is the largest planet in our solar system?</td>\n      <td>Jupiter</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>What is the boiling point of water in Celsius?</td>\n      <td>100</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# tokenize\n\ndef tokenize(text):\n    text = text.lower()\n    text = text.replace('?','')\n    text = text.replace(\"'\",\"\")\n    return text.split()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T19:55:35.306702Z","iopub.execute_input":"2025-06-29T19:55:35.307103Z","iopub.status.idle":"2025-06-29T19:55:35.312764Z","shell.execute_reply.started":"2025-06-29T19:55:35.307074Z","shell.execute_reply":"2025-06-29T19:55:35.311627Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"tokenize(\"What's your name?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T19:55:49.050256Z","iopub.execute_input":"2025-06-29T19:55:49.050616Z","iopub.status.idle":"2025-06-29T19:55:49.058099Z","shell.execute_reply.started":"2025-06-29T19:55:49.050592Z","shell.execute_reply":"2025-06-29T19:55:49.057117Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"['whats', 'your', 'name']"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"tokenize('What is the capital of France?')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T19:56:03.023107Z","iopub.execute_input":"2025-06-29T19:56:03.023562Z","iopub.status.idle":"2025-06-29T19:56:03.031735Z","shell.execute_reply.started":"2025-06-29T19:56:03.023527Z","shell.execute_reply":"2025-06-29T19:56:03.030537Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"['what', 'is', 'the', 'capital', 'of', 'france']"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# vocab \nvocab = {'<UNK>':0}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T19:56:31.080768Z","iopub.execute_input":"2025-06-29T19:56:31.081252Z","iopub.status.idle":"2025-06-29T19:56:31.086164Z","shell.execute_reply.started":"2025-06-29T19:56:31.081227Z","shell.execute_reply":"2025-06-29T19:56:31.085081Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def build_vocab(row):\n    tokenized_question = tokenize(row['question'])\n    tokenized_answer = tokenize(row['answer'])\n\n    merged_tokens = tokenized_question + tokenized_answer\n\n    for token in merged_tokens:\n        if token not in vocab:\n            vocab[token]=len(vocab)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T19:59:01.764023Z","iopub.execute_input":"2025-06-29T19:59:01.764380Z","iopub.status.idle":"2025-06-29T19:59:01.770175Z","shell.execute_reply.started":"2025-06-29T19:59:01.764358Z","shell.execute_reply":"2025-06-29T19:59:01.769170Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"df.apply(build_vocab,axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T19:59:18.561109Z","iopub.execute_input":"2025-06-29T19:59:18.561408Z","iopub.status.idle":"2025-06-29T19:59:18.572518Z","shell.execute_reply.started":"2025-06-29T19:59:18.561386Z","shell.execute_reply":"2025-06-29T19:59:18.571531Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"0     None\n1     None\n2     None\n3     None\n4     None\n      ... \n85    None\n86    None\n87    None\n88    None\n89    None\nLength: 90, dtype: object"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"len(vocab)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T19:59:32.362461Z","iopub.execute_input":"2025-06-29T19:59:32.362742Z","iopub.status.idle":"2025-06-29T19:59:32.369716Z","shell.execute_reply.started":"2025-06-29T19:59:32.362723Z","shell.execute_reply":"2025-06-29T19:59:32.368719Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"324"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"vocab","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T19:59:47.890066Z","iopub.execute_input":"2025-06-29T19:59:47.890349Z","iopub.status.idle":"2025-06-29T19:59:47.900249Z","shell.execute_reply.started":"2025-06-29T19:59:47.890329Z","shell.execute_reply":"2025-06-29T19:59:47.899399Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{'<UNK>': 0,\n 'what': 1,\n 'is': 2,\n 'the': 3,\n 'capital': 4,\n 'of': 5,\n 'france': 6,\n 'paris': 7,\n 'germany': 8,\n 'berlin': 9,\n 'who': 10,\n 'wrote': 11,\n 'to': 12,\n 'kill': 13,\n 'a': 14,\n 'mockingbird': 15,\n 'harper-lee': 16,\n 'largest': 17,\n 'planet': 18,\n 'in': 19,\n 'our': 20,\n 'solar': 21,\n 'system': 22,\n 'jupiter': 23,\n 'boiling': 24,\n 'point': 25,\n 'water': 26,\n 'celsius': 27,\n '100': 28,\n 'painted': 29,\n 'mona': 30,\n 'lisa': 31,\n 'leonardo-da-vinci': 32,\n 'square': 33,\n 'root': 34,\n '64': 35,\n '8': 36,\n 'chemical': 37,\n 'symbol': 38,\n 'for': 39,\n 'gold': 40,\n 'au': 41,\n 'which': 42,\n 'year': 43,\n 'did': 44,\n 'world': 45,\n 'war': 46,\n 'ii': 47,\n 'end': 48,\n '1945': 49,\n 'longest': 50,\n 'river': 51,\n 'nile': 52,\n 'japan': 53,\n 'tokyo': 54,\n 'developed': 55,\n 'theory': 56,\n 'relativity': 57,\n 'albert-einstein': 58,\n 'freezing': 59,\n 'fahrenheit': 60,\n '32': 61,\n 'known': 62,\n 'as': 63,\n 'red': 64,\n 'mars': 65,\n 'author': 66,\n '1984': 67,\n 'george-orwell': 68,\n 'currency': 69,\n 'united': 70,\n 'kingdom': 71,\n 'pound': 72,\n 'india': 73,\n 'delhi': 74,\n 'discovered': 75,\n 'gravity': 76,\n 'newton': 77,\n 'how': 78,\n 'many': 79,\n 'continents': 80,\n 'are': 81,\n 'there': 82,\n 'on': 83,\n 'earth': 84,\n '7': 85,\n 'gas': 86,\n 'do': 87,\n 'plants': 88,\n 'use': 89,\n 'photosynthesis': 90,\n 'co2': 91,\n 'smallest': 92,\n 'prime': 93,\n 'number': 94,\n '2': 95,\n 'invented': 96,\n 'telephone': 97,\n 'alexander-graham-bell': 98,\n 'australia': 99,\n 'canberra': 100,\n 'ocean': 101,\n 'pacific-ocean': 102,\n 'speed': 103,\n 'light': 104,\n 'vacuum': 105,\n '299,792,458m/s': 106,\n 'language': 107,\n 'spoken': 108,\n 'brazil': 109,\n 'portuguese': 110,\n 'penicillin': 111,\n 'alexander-fleming': 112,\n 'canada': 113,\n 'ottawa': 114,\n 'mammal': 115,\n 'whale': 116,\n 'element': 117,\n 'has': 118,\n 'atomic': 119,\n '1': 120,\n 'hydrogen': 121,\n 'tallest': 122,\n 'mountain': 123,\n 'everest': 124,\n 'city': 125,\n 'big': 126,\n 'apple': 127,\n 'newyork': 128,\n 'planets': 129,\n 'starry': 130,\n 'night': 131,\n 'vangogh': 132,\n 'formula': 133,\n 'h2o': 134,\n 'italy': 135,\n 'rome': 136,\n 'country': 137,\n 'famous': 138,\n 'sushi': 139,\n 'was': 140,\n 'first': 141,\n 'person': 142,\n 'step': 143,\n 'moon': 144,\n 'armstrong': 145,\n 'main': 146,\n 'ingredient': 147,\n 'guacamole': 148,\n 'avocado': 149,\n 'sides': 150,\n 'does': 151,\n 'hexagon': 152,\n 'have': 153,\n '6': 154,\n 'china': 155,\n 'yuan': 156,\n 'pride': 157,\n 'and': 158,\n 'prejudice': 159,\n 'jane-austen': 160,\n 'iron': 161,\n 'fe': 162,\n 'hardest': 163,\n 'natural': 164,\n 'substance': 165,\n 'diamond': 166,\n 'continent': 167,\n 'by': 168,\n 'area': 169,\n 'asia': 170,\n 'president': 171,\n 'states': 172,\n 'george-washington': 173,\n 'bird': 174,\n 'its': 175,\n 'ability': 176,\n 'mimic': 177,\n 'sounds': 178,\n 'parrot': 179,\n 'longest-running': 180,\n 'animated': 181,\n 'tv': 182,\n 'show': 183,\n 'simpsons': 184,\n 'vaticancity': 185,\n 'most': 186,\n 'moons': 187,\n 'saturn': 188,\n 'romeo': 189,\n 'juliet': 190,\n 'shakespeare': 191,\n 'earths': 192,\n 'atmosphere': 193,\n 'nitrogen': 194,\n 'bones': 195,\n 'adult': 196,\n 'human': 197,\n 'body': 198,\n '206': 199,\n 'metal': 200,\n 'liquid': 201,\n 'at': 202,\n 'room': 203,\n 'temperature': 204,\n 'mercury': 205,\n 'russia': 206,\n 'moscow': 207,\n 'electricity': 208,\n 'benjamin-franklin': 209,\n 'second-largest': 210,\n 'land': 211,\n 'color': 212,\n 'ripe': 213,\n 'banana': 214,\n 'yellow': 215,\n 'month': 216,\n '28': 217,\n 'days': 218,\n 'common': 219,\n 'february': 220,\n 'study': 221,\n 'living': 222,\n 'organisms': 223,\n 'called': 224,\n 'biology': 225,\n 'home': 226,\n 'great': 227,\n 'wall': 228,\n 'bees': 229,\n 'collect': 230,\n 'from': 231,\n 'flowers': 232,\n 'nectar': 233,\n 'opposite': 234,\n 'day': 235,\n 'south': 236,\n 'korea': 237,\n 'seoul': 238,\n 'bulb': 239,\n 'edison': 240,\n 'humans': 241,\n 'breathe': 242,\n 'survival': 243,\n 'oxygen': 244,\n '144': 245,\n '12': 246,\n 'pyramids': 247,\n 'giza': 248,\n 'egypt': 249,\n 'sea': 250,\n 'creature': 251,\n 'eight': 252,\n 'arms': 253,\n 'octopus': 254,\n 'holiday': 255,\n 'celebrated': 256,\n 'december': 257,\n '25': 258,\n 'christmas': 259,\n 'yen': 260,\n 'legs': 261,\n 'spider': 262,\n 'sport': 263,\n 'uses': 264,\n 'net,': 265,\n 'ball,': 266,\n 'hoop': 267,\n 'basketball': 268,\n 'kangaroos': 269,\n 'female': 270,\n 'minister': 271,\n 'uk': 272,\n 'margaretthatcher': 273,\n 'fastest': 274,\n 'animal': 275,\n 'cheetah': 276,\n 'periodic': 277,\n 'table': 278,\n 'spain': 279,\n 'madrid': 280,\n 'closest': 281,\n 'sun': 282,\n 'father': 283,\n 'computers': 284,\n 'charlesbabbage': 285,\n 'mexico': 286,\n 'mexicocity': 287,\n 'colors': 288,\n 'rainbow': 289,\n 'musical': 290,\n 'instrument': 291,\n 'black': 292,\n 'white': 293,\n 'keys': 294,\n 'piano': 295,\n 'americas': 296,\n '1492': 297,\n 'christophercolumbus': 298,\n 'disney': 299,\n 'character': 300,\n 'long': 301,\n 'nose': 302,\n 'grows': 303,\n 'it': 304,\n 'when': 305,\n 'lying': 306,\n 'pinocchio': 307,\n 'directed': 308,\n 'movie': 309,\n 'titanic': 310,\n 'jamescameron': 311,\n 'superhero': 312,\n 'also': 313,\n 'dark': 314,\n 'knight': 315,\n 'batman': 316,\n 'brasilia': 317,\n 'fruit': 318,\n 'king': 319,\n 'fruits': 320,\n 'mango': 321,\n 'eiffel': 322,\n 'tower': 323}"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# convert words to numerical indices\n\ndef text_to_indices(text,vocab):\n\n    indexed_text = []\n\n    for token in tokenize(text):\n\n        if token in vocab:\n            indexed_text.append(vocab[token])\n        else:\n            indexed_text.append(vocab['<UNK>'])\n\n    return indexed_text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T20:01:46.792518Z","iopub.execute_input":"2025-06-29T20:01:46.793402Z","iopub.status.idle":"2025-06-29T20:01:46.798814Z","shell.execute_reply.started":"2025-06-29T20:01:46.793372Z","shell.execute_reply":"2025-06-29T20:01:46.797606Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"text_to_indices(\"What is Rp study point\",vocab)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T20:02:09.070293Z","iopub.execute_input":"2025-06-29T20:02:09.070745Z","iopub.status.idle":"2025-06-29T20:02:09.077392Z","shell.execute_reply.started":"2025-06-29T20:02:09.070718Z","shell.execute_reply":"2025-06-29T20:02:09.076500Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"[1, 2, 0, 221, 25]"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"import torch \nfrom torch.utils.data import Dataset, DataLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T20:03:38.481473Z","iopub.execute_input":"2025-06-29T20:03:38.482467Z","iopub.status.idle":"2025-06-29T20:03:44.033273Z","shell.execute_reply.started":"2025-06-29T20:03:38.482427Z","shell.execute_reply":"2025-06-29T20:03:44.032170Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"class CustomDataset(Dataset):\n\n    def __init__(self,df,vocab):\n        self.df = df\n        self.vocab = vocab\n\n    def __len__(self):\n        return self.df.shape[0]\n\n    def __getitem__(self,index):\n\n        numerical_question = text_to_indices(self.df.iloc[index]['question'],self.vocab)\n        numerical_answer = text_to_indices(self.df.iloc[index]['answer'],self.vocab)\n        return torch.tensor(numerical_question), torch.tensor(numerical_answer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T20:08:07.716304Z","iopub.execute_input":"2025-06-29T20:08:07.716836Z","iopub.status.idle":"2025-06-29T20:08:07.724125Z","shell.execute_reply.started":"2025-06-29T20:08:07.716810Z","shell.execute_reply":"2025-06-29T20:08:07.722958Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"dataset = CustomDataset(df,vocab)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T20:08:36.527759Z","iopub.execute_input":"2025-06-29T20:08:36.528160Z","iopub.status.idle":"2025-06-29T20:08:36.532980Z","shell.execute_reply.started":"2025-06-29T20:08:36.528137Z","shell.execute_reply":"2025-06-29T20:08:36.531965Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"dataloader = DataLoader(dataset, batch_size=1, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T20:08:59.096003Z","iopub.execute_input":"2025-06-29T20:08:59.096302Z","iopub.status.idle":"2025-06-29T20:08:59.101519Z","shell.execute_reply.started":"2025-06-29T20:08:59.096283Z","shell.execute_reply":"2025-06-29T20:08:59.100472Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"for question,answer in dataloader:\n    print(question,answer[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T20:09:43.545698Z","iopub.execute_input":"2025-06-29T20:09:43.546319Z","iopub.status.idle":"2025-06-29T20:09:43.602348Z","shell.execute_reply.started":"2025-06-29T20:09:43.546285Z","shell.execute_reply":"2025-06-29T20:09:43.601385Z"}},"outputs":[{"name":"stdout","text":"tensor([[ 42, 117, 118,   3, 119,  94, 120]]) tensor([121])\ntensor([[ 10,  75, 111]]) tensor([112])\ntensor([[ 42, 263, 264,  14, 265, 266, 158, 267]]) tensor([268])\ntensor([[1, 2, 3, 4, 5, 8]]) tensor([9])\ntensor([[  1,   2,   3,   4,   5, 236, 237]]) tensor([238])\ntensor([[  1,   2,   3,  33,  34,   5, 245]]) tensor([246])\ntensor([[ 42,  18,   2,   3, 281,  12,   3, 282]]) tensor([205])\ntensor([[ 10,  96,   3, 104, 239]]) tensor([240])\ntensor([[  1,   2,   3, 122, 123,  19,   3,  45]]) tensor([124])\ntensor([[ 78,  79, 261, 151,  14, 262, 153]]) tensor([36])\ntensor([[  1,   2,   3,   4,   5, 286]]) tensor([287])\ntensor([[ 78,  79, 129,  81,  19,   3,  21,  22]]) tensor([36])\ntensor([[  1,   2,   3, 221,   5, 222, 223, 224]]) tensor([225])\ntensor([[  1,   2,   3, 163, 164, 165,  83,  84]]) tensor([166])\ntensor([[10, 55,  3, 56,  5, 57]]) tensor([58])\ntensor([[ 10,  75,   3, 296,  19, 297]]) tensor([298])\ntensor([[  1,   2,   3, 146, 147,  19, 148]]) tensor([149])\ntensor([[42, 43, 44, 45, 46, 47, 48]]) tensor([49])\ntensor([[  1,   2,   3,   4,   5, 135]]) tensor([136])\ntensor([[ 42, 216, 118, 217, 218,  19,  14, 219,  43]]) tensor([220])\ntensor([[ 42,  86,  87, 241, 242,  19,  39, 243]]) tensor([244])\ntensor([[ 10, 140,   3, 141, 171,   5,   3,  70, 172]]) tensor([173])\ntensor([[  1,   2,   3, 141, 117,  83,   3, 277, 278]]) tensor([121])\ntensor([[10, 96,  3, 97]]) tensor([98])\ntensor([[ 1,  2,  3,  4,  5, 73]]) tensor([74])\ntensor([[ 10,  75, 208]]) tensor([209])\ntensor([[ 1,  2,  3, 50, 51, 19,  3, 45]]) tensor([52])\ntensor([[ 42, 137,   2, 138,  39, 139]]) tensor([53])\ntensor([[  1,   2,   3, 212,   5,  14, 213, 214]]) tensor([215])\ntensor([[ 42, 137,   2, 138,  39, 175, 269]]) tensor([99])\ntensor([[ 10, 140,   3, 141, 270,  93, 271,   5,   3, 272]]) tensor([273])\ntensor([[ 1,  2,  3, 92, 93, 94]]) tensor([95])\ntensor([[ 1,  2,  3, 33, 34,  5, 35]]) tensor([36])\ntensor([[10, 75, 76]]) tensor([77])\ntensor([[ 1,  2,  3, 37, 38, 39, 40]]) tensor([41])\ntensor([[ 10,  29, 130, 131]]) tensor([132])\ntensor([[ 42, 125,   2,  62,  63,   3, 126, 127]]) tensor([128])\ntensor([[ 42,  18, 118,   3, 186, 187]]) tensor([188])\ntensor([[42, 86, 87, 88, 89, 39, 90]]) tensor([91])\ntensor([[ 1,  2,  3, 69,  5,  3, 70, 71]]) tensor([72])\ntensor([[ 42, 174,   2,  62,  39, 175, 176,  12, 177, 178]]) tensor([179])\ntensor([[ 1,  2,  3, 17, 18, 19, 20, 21, 22]]) tensor([23])\ntensor([[  1,   2,   3, 234,   5, 235]]) tensor([131])\ntensor([[1, 2, 3, 4, 5, 6]]) tensor([7])\ntensor([[ 1,  2,  3,  4,  5, 53]]) tensor([54])\ntensor([[ 42, 137,   2,  62,  39,   3, 322, 323]]) tensor([6])\ntensor([[ 78,  79, 150, 151,  14, 152, 153]]) tensor([154])\ntensor([[ 10,  11, 157, 158, 159]]) tensor([160])\ntensor([[ 1,  2,  3, 69,  5, 53]]) tensor([260])\ntensor([[10,  2,  3, 66,  5, 67]]) tensor([68])\ntensor([[ 42, 200,   2,  14, 201, 202, 203, 204]]) tensor([205])\ntensor([[  1,   2,   3,  92, 137,  19,   3,  45]]) tensor([185])\ntensor([[78, 79, 80, 81, 82, 83, 84]]) tensor([85])\ntensor([[ 42, 290, 291, 118, 292, 158, 293, 294]]) tensor([295])\ntensor([[ 10, 140,   3, 141, 142,  12, 143,  83,   3, 144]]) tensor([145])\ntensor([[  1,  87, 229, 230, 231, 232]]) tensor([233])\ntensor([[ 10,  11, 189, 158, 190]]) tensor([191])\ntensor([[ 42, 250, 251, 118, 252, 253]]) tensor([254])\ntensor([[  1,   2,   3,  17, 115,  83,  84]]) tensor([116])\ntensor([[  1,   2,   3, 180, 181, 182, 183]]) tensor([184])\ntensor([[ 42, 255,   2, 256,  83, 257, 258]]) tensor([259])\ntensor([[ 42,   2,   3, 210, 137, 168, 211, 169]]) tensor([113])\ntensor([[ 42, 312,   2, 313,  62,  63,   3, 314, 315]]) tensor([316])\ntensor([[ 1,  2,  3,  4,  5, 99]]) tensor([100])\ntensor([[ 42, 107,   2, 108,  19, 109]]) tensor([110])\ntensor([[  1,   2,   3, 103,   5, 104,  19, 105]]) tensor([106])\ntensor([[  1,   2,   3,  69,   5, 155]]) tensor([156])\ntensor([[ 1,  2,  3, 59, 25,  5, 26, 19, 60]]) tensor([61])\ntensor([[ 78,  79, 288,  81,  19,  14, 289]]) tensor([85])\ntensor([[ 42, 101,   2,   3,  17]]) tensor([102])\ntensor([[42, 18,  2, 62, 63,  3, 64, 18]]) tensor([65])\ntensor([[  1,   2,   3,   4,   5, 279]]) tensor([280])\ntensor([[ 42,   2,   3, 274, 211, 275]]) tensor([276])\ntensor([[  1,   2,   3,  37, 133,   5,  26]]) tensor([134])\ntensor([[ 42, 137, 118,   3, 247,   5, 248]]) tensor([249])\ntensor([[ 42, 299, 300, 118,  14, 301, 302, 158, 303, 304, 305, 306]]) tensor([307])\ntensor([[  1,   2,   3,  37,  38,  39, 161]]) tensor([162])\ntensor([[ 42, 167,   2,   3,  17, 168, 169]]) tensor([170])\ntensor([[ 42, 137,   2, 226,  12,   3, 227, 228]]) tensor([155])\ntensor([[10, 29,  3, 30, 31]]) tensor([32])\ntensor([[  1,   2,   3,   4,   5, 113]]) tensor([114])\ntensor([[ 10, 308,   3, 309, 310]]) tensor([311])\ntensor([[  1,   2,   3,   4,   5, 206]]) tensor([207])\ntensor([[ 10,   2,  62,  63,   3, 283,   5, 284]]) tensor([285])\ntensor([[ 1,  2,  3, 24, 25,  5, 26, 19, 27]]) tensor([28])\ntensor([[  1,   2,   3, 146,  86,  19, 192, 193]]) tensor([194])\ntensor([[ 42, 318,   2,  62,  63,   3, 319,   5, 320]]) tensor([321])\ntensor([[ 78,  79, 195,  81,  19,   3, 196, 197, 198]]) tensor([199])\ntensor([[10, 11, 12, 13, 14, 15]]) tensor([16])\ntensor([[  1,   2,   3,   4,   5, 109]]) tensor([317])\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"import torch.nn as nn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T20:09:56.352905Z","iopub.execute_input":"2025-06-29T20:09:56.353298Z","iopub.status.idle":"2025-06-29T20:09:56.358479Z","shell.execute_reply.started":"2025-06-29T20:09:56.353275Z","shell.execute_reply":"2025-06-29T20:09:56.357249Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"class SimpleRNN(nn.Module):\n\n    def __init__(self,vocab_size):\n\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size,embedding_dim=50)\n        self.rnn = nn.RNN(50,64,batch_first=True)\n        self.fc = nn.Linear(64,vocab_size)\n\n    def forward(self,question):\n        embedded_question = self.embedding(question)\n        hidden, final = self.rnn(embedded_question)\n        output = self.fc(final.squeeze(0))\n        return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T20:12:56.153358Z","iopub.execute_input":"2025-06-29T20:12:56.154269Z","iopub.status.idle":"2025-06-29T20:12:56.160082Z","shell.execute_reply.started":"2025-06-29T20:12:56.154237Z","shell.execute_reply":"2025-06-29T20:12:56.159004Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"x = nn.Embedding(324, embedding_dim=50)\ny = nn.RNN(50, 64, batch_first=True)\nz = nn.Linear(64, 324)\n\na = dataset[0][0].reshape(1,6)\nprint(\"shape of a:\", a.shape)\nb = x(a)\nprint(\"shape of b:\", b.shape)\nc, d = y(b)\nprint(\"shape of c:\", c.shape)\nprint(\"shape of d:\", d.shape)\n\ne = z(d.squeeze(0))\n\nprint(\"shape of e:\", e.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T20:14:05.692728Z","iopub.execute_input":"2025-06-29T20:14:05.693071Z","iopub.status.idle":"2025-06-29T20:14:05.703639Z","shell.execute_reply.started":"2025-06-29T20:14:05.693048Z","shell.execute_reply":"2025-06-29T20:14:05.702852Z"}},"outputs":[{"name":"stdout","text":"shape of a: torch.Size([1, 6])\nshape of b: torch.Size([1, 6, 50])\nshape of c: torch.Size([1, 6, 64])\nshape of d: torch.Size([1, 1, 64])\nshape of e: torch.Size([1, 324])\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"learning_rate = 0.001\nepochs = 20","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T20:14:29.282493Z","iopub.execute_input":"2025-06-29T20:14:29.282780Z","iopub.status.idle":"2025-06-29T20:14:29.287243Z","shell.execute_reply.started":"2025-06-29T20:14:29.282760Z","shell.execute_reply":"2025-06-29T20:14:29.286240Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"model = SimpleRNN(len(vocab))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T20:14:41.399205Z","iopub.execute_input":"2025-06-29T20:14:41.399518Z","iopub.status.idle":"2025-06-29T20:14:41.405355Z","shell.execute_reply.started":"2025-06-29T20:14:41.399495Z","shell.execute_reply":"2025-06-29T20:14:41.404460Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T20:15:29.047792Z","iopub.execute_input":"2025-06-29T20:15:29.048830Z","iopub.status.idle":"2025-06-29T20:15:32.674894Z","shell.execute_reply.started":"2025-06-29T20:15:29.048799Z","shell.execute_reply":"2025-06-29T20:15:32.674062Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# training loop\n\nfor epoch in range(epochs):\n\n  total_loss = 0\n\n  for question, answer in dataloader:\n\n    optimizer.zero_grad()\n\n    # forward pass\n    output = model(question)\n\n    # loss -> output shape (1,324) - (1)\n    loss = criterion(output, answer[0])\n\n    # gradients\n    loss.backward()\n\n    # update\n    optimizer.step()\n\n    total_loss = total_loss + loss.item()\n\n  print(f\"Epoch: {epoch+1}, Loss: {total_loss:4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T20:18:05.797407Z","iopub.execute_input":"2025-06-29T20:18:05.802105Z","iopub.status.idle":"2025-06-29T20:18:11.409666Z","shell.execute_reply.started":"2025-06-29T20:18:05.802055Z","shell.execute_reply":"2025-06-29T20:18:11.408622Z"}},"outputs":[{"name":"stdout","text":"Epoch: 1, Loss: 523.420075\nEpoch: 2, Loss: 456.454120\nEpoch: 3, Loss: 377.953644\nEpoch: 4, Loss: 317.057743\nEpoch: 5, Loss: 265.100234\nEpoch: 6, Loss: 217.611086\nEpoch: 7, Loss: 174.244534\nEpoch: 8, Loss: 135.625684\nEpoch: 9, Loss: 104.002087\nEpoch: 10, Loss: 79.147776\nEpoch: 11, Loss: 60.887804\nEpoch: 12, Loss: 47.433460\nEpoch: 13, Loss: 37.417863\nEpoch: 14, Loss: 30.444482\nEpoch: 15, Loss: 25.072430\nEpoch: 16, Loss: 20.698071\nEpoch: 17, Loss: 17.448427\nEpoch: 18, Loss: 14.870777\nEpoch: 19, Loss: 12.717108\nEpoch: 20, Loss: 11.019878\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"for epoch in range(epochs):\n    total_loss = 0\n    num_batches = 0\n\n    for question, answer in dataloader:\n        optimizer.zero_grad()\n        output = model(question)\n        loss = criterion(output, answer[0])\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        num_batches += 1\n\n    avg_loss = total_loss / num_batches\n    print(f\"Epoch: {epoch + 1}, Avg Loss: {avg_loss:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T20:20:57.382639Z","iopub.execute_input":"2025-06-29T20:20:57.383778Z","iopub.status.idle":"2025-06-29T20:21:02.892985Z","shell.execute_reply.started":"2025-06-29T20:20:57.383745Z","shell.execute_reply":"2025-06-29T20:21:02.892105Z"}},"outputs":[{"name":"stdout","text":"Epoch: 1, Avg Loss: 0.1074\nEpoch: 2, Avg Loss: 0.0946\nEpoch: 3, Avg Loss: 0.0838\nEpoch: 4, Avg Loss: 0.0746\nEpoch: 5, Avg Loss: 0.0669\nEpoch: 6, Avg Loss: 0.0603\nEpoch: 7, Avg Loss: 0.0546\nEpoch: 8, Avg Loss: 0.0498\nEpoch: 9, Avg Loss: 0.0456\nEpoch: 10, Avg Loss: 0.0417\nEpoch: 11, Avg Loss: 0.0383\nEpoch: 12, Avg Loss: 0.0352\nEpoch: 13, Avg Loss: 0.0326\nEpoch: 14, Avg Loss: 0.0302\nEpoch: 15, Avg Loss: 0.0279\nEpoch: 16, Avg Loss: 0.0260\nEpoch: 17, Avg Loss: 0.0242\nEpoch: 18, Avg Loss: 0.0226\nEpoch: 19, Avg Loss: 0.0211\nEpoch: 20, Avg Loss: 0.0197\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"def predict(model,question,threshold=0.5):\n\n    # convert question to numbers\n    numerical_question = text_to_indices(question, vocab)\n   \n    # tensor \n    question_tensor = torch.tensor(numerical_question).unsqueeze(0)\n    \n    # send to model\n    output = model(question_tensor)\n\n    # convert logits into probs\n    probs = torch.nn.functional.softmax(output,dim=1)\n\n    # find index of max prob\n    value, index = torch.max(probs, dim=1)\n\n    if value< threshold:\n        print(\"I don't know\")\n    else:\n        print(list(vocab.keys())[index])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T20:27:51.733705Z","iopub.execute_input":"2025-06-29T20:27:51.734033Z","iopub.status.idle":"2025-06-29T20:27:51.740243Z","shell.execute_reply.started":"2025-06-29T20:27:51.734012Z","shell.execute_reply":"2025-06-29T20:27:51.739414Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"predict(model, \"What is the largest planet in our solar system?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T20:27:52.046704Z","iopub.execute_input":"2025-06-29T20:27:52.047063Z","iopub.status.idle":"2025-06-29T20:27:52.052822Z","shell.execute_reply.started":"2025-06-29T20:27:52.047031Z","shell.execute_reply":"2025-06-29T20:27:52.051989Z"}},"outputs":[{"name":"stdout","text":"jupiter\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"list(vocab.keys())[7]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T20:27:52.229283Z","iopub.execute_input":"2025-06-29T20:27:52.229579Z","iopub.status.idle":"2025-06-29T20:27:52.235398Z","shell.execute_reply.started":"2025-06-29T20:27:52.229558Z","shell.execute_reply":"2025-06-29T20:27:52.234489Z"}},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"'paris'"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"list(vocab.keys())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T20:27:54.497609Z","iopub.execute_input":"2025-06-29T20:27:54.497946Z","iopub.status.idle":"2025-06-29T20:27:54.506626Z","shell.execute_reply.started":"2025-06-29T20:27:54.497905Z","shell.execute_reply":"2025-06-29T20:27:54.505649Z"}},"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"['<UNK>',\n 'what',\n 'is',\n 'the',\n 'capital',\n 'of',\n 'france',\n 'paris',\n 'germany',\n 'berlin',\n 'who',\n 'wrote',\n 'to',\n 'kill',\n 'a',\n 'mockingbird',\n 'harper-lee',\n 'largest',\n 'planet',\n 'in',\n 'our',\n 'solar',\n 'system',\n 'jupiter',\n 'boiling',\n 'point',\n 'water',\n 'celsius',\n '100',\n 'painted',\n 'mona',\n 'lisa',\n 'leonardo-da-vinci',\n 'square',\n 'root',\n '64',\n '8',\n 'chemical',\n 'symbol',\n 'for',\n 'gold',\n 'au',\n 'which',\n 'year',\n 'did',\n 'world',\n 'war',\n 'ii',\n 'end',\n '1945',\n 'longest',\n 'river',\n 'nile',\n 'japan',\n 'tokyo',\n 'developed',\n 'theory',\n 'relativity',\n 'albert-einstein',\n 'freezing',\n 'fahrenheit',\n '32',\n 'known',\n 'as',\n 'red',\n 'mars',\n 'author',\n '1984',\n 'george-orwell',\n 'currency',\n 'united',\n 'kingdom',\n 'pound',\n 'india',\n 'delhi',\n 'discovered',\n 'gravity',\n 'newton',\n 'how',\n 'many',\n 'continents',\n 'are',\n 'there',\n 'on',\n 'earth',\n '7',\n 'gas',\n 'do',\n 'plants',\n 'use',\n 'photosynthesis',\n 'co2',\n 'smallest',\n 'prime',\n 'number',\n '2',\n 'invented',\n 'telephone',\n 'alexander-graham-bell',\n 'australia',\n 'canberra',\n 'ocean',\n 'pacific-ocean',\n 'speed',\n 'light',\n 'vacuum',\n '299,792,458m/s',\n 'language',\n 'spoken',\n 'brazil',\n 'portuguese',\n 'penicillin',\n 'alexander-fleming',\n 'canada',\n 'ottawa',\n 'mammal',\n 'whale',\n 'element',\n 'has',\n 'atomic',\n '1',\n 'hydrogen',\n 'tallest',\n 'mountain',\n 'everest',\n 'city',\n 'big',\n 'apple',\n 'newyork',\n 'planets',\n 'starry',\n 'night',\n 'vangogh',\n 'formula',\n 'h2o',\n 'italy',\n 'rome',\n 'country',\n 'famous',\n 'sushi',\n 'was',\n 'first',\n 'person',\n 'step',\n 'moon',\n 'armstrong',\n 'main',\n 'ingredient',\n 'guacamole',\n 'avocado',\n 'sides',\n 'does',\n 'hexagon',\n 'have',\n '6',\n 'china',\n 'yuan',\n 'pride',\n 'and',\n 'prejudice',\n 'jane-austen',\n 'iron',\n 'fe',\n 'hardest',\n 'natural',\n 'substance',\n 'diamond',\n 'continent',\n 'by',\n 'area',\n 'asia',\n 'president',\n 'states',\n 'george-washington',\n 'bird',\n 'its',\n 'ability',\n 'mimic',\n 'sounds',\n 'parrot',\n 'longest-running',\n 'animated',\n 'tv',\n 'show',\n 'simpsons',\n 'vaticancity',\n 'most',\n 'moons',\n 'saturn',\n 'romeo',\n 'juliet',\n 'shakespeare',\n 'earths',\n 'atmosphere',\n 'nitrogen',\n 'bones',\n 'adult',\n 'human',\n 'body',\n '206',\n 'metal',\n 'liquid',\n 'at',\n 'room',\n 'temperature',\n 'mercury',\n 'russia',\n 'moscow',\n 'electricity',\n 'benjamin-franklin',\n 'second-largest',\n 'land',\n 'color',\n 'ripe',\n 'banana',\n 'yellow',\n 'month',\n '28',\n 'days',\n 'common',\n 'february',\n 'study',\n 'living',\n 'organisms',\n 'called',\n 'biology',\n 'home',\n 'great',\n 'wall',\n 'bees',\n 'collect',\n 'from',\n 'flowers',\n 'nectar',\n 'opposite',\n 'day',\n 'south',\n 'korea',\n 'seoul',\n 'bulb',\n 'edison',\n 'humans',\n 'breathe',\n 'survival',\n 'oxygen',\n '144',\n '12',\n 'pyramids',\n 'giza',\n 'egypt',\n 'sea',\n 'creature',\n 'eight',\n 'arms',\n 'octopus',\n 'holiday',\n 'celebrated',\n 'december',\n '25',\n 'christmas',\n 'yen',\n 'legs',\n 'spider',\n 'sport',\n 'uses',\n 'net,',\n 'ball,',\n 'hoop',\n 'basketball',\n 'kangaroos',\n 'female',\n 'minister',\n 'uk',\n 'margaretthatcher',\n 'fastest',\n 'animal',\n 'cheetah',\n 'periodic',\n 'table',\n 'spain',\n 'madrid',\n 'closest',\n 'sun',\n 'father',\n 'computers',\n 'charlesbabbage',\n 'mexico',\n 'mexicocity',\n 'colors',\n 'rainbow',\n 'musical',\n 'instrument',\n 'black',\n 'white',\n 'keys',\n 'piano',\n 'americas',\n '1492',\n 'christophercolumbus',\n 'disney',\n 'character',\n 'long',\n 'nose',\n 'grows',\n 'it',\n 'when',\n 'lying',\n 'pinocchio',\n 'directed',\n 'movie',\n 'titanic',\n 'jamescameron',\n 'superhero',\n 'also',\n 'dark',\n 'knight',\n 'batman',\n 'brasilia',\n 'fruit',\n 'king',\n 'fruits',\n 'mango',\n 'eiffel',\n 'tower']"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}